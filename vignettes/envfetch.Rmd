---
title: "envfetch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{envfetch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  out.width = "100%"
)

strip_ansi <- function(input_string) {
  cleaned_string <- gsub("[ ]*\\[[0-9]+m", "", input_string)
  return(cleaned_string)
}

# Combine output and messages for accurate readme preview
asconsole_output <- NULL
knitr::knit_hooks$set(message = function(x, options) {
  # Strip ANSI codes
  x <- strip_ansi(x)
  
  if(!is.null(options$output)) {
    if(options$output == 'asconsole') {
      asconsole_output <<- c(asconsole_output, x)
      return(NULL)
    }
  }
  
  knitr::hooks_html()$message(x, options)
})

knitr::knit_hooks$set(output = function(x, options) {
  # Strip ANSI codes
  x <- strip_ansi(x)
  
  if(!is.null(options$output)) {
    if(options$output == 'asconsole') {
      asconsole_output <<- c(asconsole_output, x)
      return(NULL)
    }
  }
  
  knitr::hooks_html()$output(x, options)
})

knitr::knit_hooks$set(chunk = function(x, options) {
  if(!is.null(options$output)) {
    if(options$output == 'asconsole') {
      y <- paste(asconsole_output, collapse = "")
      # Strip ANSI codes
      y <- strip_ansi(y)
      
      y <- knitr::hooks_html()$output(y, options)
      asconsole_output <<- NULL
      y <- paste(x, y, collapse = "")
      return(y)
    }
  }
  
  knitr::hooks_html()$chunk(x, options)
})
```

## Introduction
The envfetch package is designed to extract, and summarise environmental data across time and space using `sf` points or polygons. It offers an effective way to handle data extraction from local files and Google Earth Engine.

This vignette demonstrates the usage of envfetch package functions using a synthetic dataset.

### 1. Setup `sf` collection

Use of envfetch starts with an `sf` collection with a time column. For this example, we will use the `throw` function to create an `sf` collection containing a grid of points over Australia for a range of times. If you have your own data, load that in as a variable called `d` to continue with the example.

```{r}
library(envfetch)

d <- throw(
  offset=c(128, -30),
  cellsize=1,
  n=10,
  time_interval=lubridate::interval(start='2017-01-01', end='2017-01-02'),
)
```

The data set should look like the following:

```{r}
summary(d)
```

Each row of the `sf` collection should have an `sf::geometry` along with a `datetime`. The `geometry` may be a point or a polygon. The `datetime` may be a time interval (`lubridate::interval`), a date (e.g. `"20220101"`) or a datetime `"2010-08-03 00:50:50"`. Ensure data used with the envfetch package matches this format.

We can visualise our input data with a plot:

```{r, warning = FALSE}
library(ggplot2)
library(rnaturalearth)
library(rnaturalearthdata)

# load map of australia for reference
world <- ne_countries(scale = "medium", returnclass = "sf")
australia <- subset(world, admin == "Australia")

ggplot(data = australia) +
  geom_sf() +
  geom_sf(data = d, size = 1, show.legend = "point") +
  ggtitle("Australia with sample points") +
  theme_minimal()
```


### 2. Extract from local rasters or google earth engine with `envfetch`

**`envfetch`**:

-   extracts and summarises data over space (within each `sf` geometry) and time 
    (at each time or within each time range) of your input,
-   provides a simple function to extract from local files or google earth engine (at the fastest possible speeds, see our [benchmark]()),
-   ensures you don't overuse memory on your machine or google earth engine,
-   caches progress, so you don't have to re-extract the same thing twice and
-   allows you to repeat sampling over different times (see section 3, below).


To fetch the data, supply `envfetch` with your data source. Here, you can extract
from a local netcdf data set. To extract your own raster file, replace
`example_nc_path` with the path of your local raster file, such as `'/path/to/netcdf.nc'`.

```{r, output='asconsole'}
example_nc_path <- system.file("extdata", "example.nc", package = "envfetch")
extracted <- envfetch(x = d, r = example_nc_path)
```

or from a data set hosted on google earth engine.

```{r, output='asconsole'}
extracted <- envfetch(x = d, r = 'MODIS/061/MOD13Q1', use_cache=F)
```

If you want to extract from multiple data sets at once, specify multiple items
with a list. As we've already calculated these, they are loaded from the cache
instantly:

```{r, output='asconsole'}
extracted <- envfetch(
  x = d, 
  r = list(
    example_nc_path,
    'MODIS/061/MOD13Q1'
  )
)
```

If you want to change the default `mean` summarisation behaviour (e.g., calculate the
`mean` for one raster and the `sum` for the other) or extract from specific bands
of your data, specify some custom parameters:

```{r, output='asconsole'}
extracted <- envfetch(
  x = d, 
  r = list(
    example_nc_path,
    'MODIS/061/MOD13Q1'
  ),
  bands = list(
    'precip',
    c('NDVI', 'DetailedQA')
  ),
  temporal_fun = list(
    'sum',
    'mean'
  )
)
```


### 3. Obtain data for repeated time intervals

In certain applications, you may need to obtain environmental data from repeated previous time intervals. For example, we can extract data from the past six months relative to the time (start time if an interval is provided) of each data point, with a summary calculated for each two-week block, using the **`.time_rep`** variable.

```{r, eval=FALSE}
rep_extracted <- envfetch(
  x = d, 
  r = list(
    '/path/to/netcdf.nc',
    'MODIS/061/MOD13Q1'
  ),
  bands = list(
    'precip',
    c('NDVI', 'DetailedQA')
  ),
  temporal_fun = list(
    sum,
    mean
  ),
  .time_rep=time_rep(interval=lubridate::days(14), n_start=-12)
)
```

